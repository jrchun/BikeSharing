---
title: "Bike Sharing Demand"
author: "Cheon"
date: "2018년 10월 6일"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setlocale('LC_ALL','C') #에러방지
```

#**자전거 대여 수요예측 분석**
 본 문서는 Kaggle에 업로드된 '자전거 수요예측 분석'(Bike Sharing Demand)을 마크다운형식으로 편집하여,  
Github에 업로드 하기 위하여 작성된 문서입니다.  
 데이터 출처
 *<https://www.kaggle.com/c/bike-sharing-demand>  

---   

## 분석 과정 목차  

 [1. 변수 정의](#변수-정의)  
 
 [2. 분석 과정](#분석-과정)  
 
  [데이터 구조 확인](#데이터-구조-확인)  
    
  [사전 가설 수립(Make insight)](#가설-사전-수립)  
    
  [EDA](#Exproratory-Data-Analysis)  
  
  [Data preprocessing](#Data-Preprocessing)  
    
  [Modeling](#Modeling)  
    
 [3. 결론](#한계점)  
 
 
---  

## 변수 정의  

 1. datetime - hourly date + timestamp  

 2. season  
    * 1 : spring  
    * 2 : summer  
    * 3 : fall  
    * 4 : winter 

 3. holiday - whether the day is considered a holiday (휴일)

 4. workingday - whether the day is neither a weekend nor holiday (주말도, 휴일도 아닌 날)

 5. weather  
    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy  
    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  
    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  
    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  
 6. temp - temperature in Celsius(섭씨) -> 실제온도.

 7. atemp - "feels like" temperature in Celsius (체감온도)

 8. humidity - relative humidity (습기)

 9. windspeed - wind speed (풍속)

**Train에만 있는 것. (종속변수)**    

  * casual - number of non-registered user rentals initiated   (비회원의 렌탈수)

  * registered - number of registered user rentals initiated   (회원의 렌탈수)

  * count - number of total rentals (토탈렌트)

  
---  


## 분석 과정   


### 데이터 구조 확인  
**Initialize**  

```{r}

rm(list=ls())
library(ggplot2)  #for plotting
library(corrplot) #for correlation plot
library(dplyr)    #for %in% function
library(caret)    #for cross validation
library(pscl)     #for Zero-inflated poisson regression
library(gridExtra)
library(rpart) # train : CART
library(party) #train : ctree
library(randomForest) # train : rf
library(e1071) #train : ranger(rf보다 빠른 속도)
library(ranger) #train : ranger(rf보다 빠른 속도)
library(elasticnet) #train : ridge
library(car) # for vif function(multicollinearity)
setwd('C:\\github\\Project\\BikeSharing')
train <- read.csv('train.csv', stringsAsFactors = F)
test <- read.csv('test.csv', stringsAsFactors = F)

```

```{r}  
colSums(is.na(train))
colSums(is.na(test))
str(c(train, test))
```
  
---

-> NA값은 존재하지 않는다는 것을 확인할 수 있다.  

### 가설 사전 수립  

**Idea 1. train과 test 데이터의 차이점**  


train data에 비하여 test데이터는 casual(비회원의 렌트 수)와 registered(회원의 렌트 수)가 존재하지 않는다.  
결국 count는 전체의 렌트 수 이므로, 두개의 모델을 적합시켜서 각각에서의 비회원 / 회원의 렌트수를 예측 한 이후에 그걸 더하면
좀 더 정확하지 않을까?  
아무래도 casual과 registered는 확실히 경향에 있어서 차이가 있을 것 같다.  
casual일때 더 많이 빌릴까? registered일때 더 많이 빌릴까?  
이 사람들의 특징에서는 어떠한 차이가 존재할까?


**Idea 2. 기본 가정 확인하기.**  


 우리가 원하는 종속변수는 특정한 사건(렌트)의 수를 뜻하는 정수이다.  
그렇다면 glm을 통해서 poison분포로 적합시킬 수 있지는 않을까?


**Idea 3. 변수간의 관계에 대해서 생각해보기.**  


  날짜에 관련된 변수가 datetime, holiday, workingday 이렇게 3개나 존재한다. (어쩌면 weather 또한 관련 되어 있을지도)  
Weather는 temp, atemp, humidity와 관계가 밀접하지 않을까?  
변수간의 Correration 확인해볼수 있을것 같다.  
  

---  

### Exproratory Data Analysis  

**Preparing Total data**  

```{r}
test[,c('casual', 'registered', 'count')] <- NA
train <- rename(train, 'y' = 'count')
test <- rename(test, 'y' = 'count')
data <- rbind(train, test)
str(data)
```  
  
  
```{r}
colSums(is.na(data))
```
**Categorical data Exploring**  

**datetime**

```{r}
nrow(data) == length(unique(data$datetime))
```

-> 문자열 데이터이며, 데이터의 분할이 필요함을 확인할 수 있다.  

```{r}
ggplot(data = data, aes(x = datetime, y = y)) +
  geom_point() +
  labs(title = 'Scatter plot of data',
       subtitle = 'With datetime(all Y)')
```

-> 각 월의 20일~마지막일 까지는 test에 포함된 NA값이다.  

따라서, 이 빈 구역들의 y값들을 예측하는 것이 목표이다.  

  
**season**  

팩터들의 이름을 부여한다.
```{r}
str(data$season)
data$season[which(data$season == 1)] <- 'spring'
data$season[which(data$season == 2)] <- 'summer'
data$season[which(data$season == 3)] <- 'fall'
data$season[which(data$season == 4)] <- 'winter'
data$season <- factor(data$season,
                         levels = c('spring', 'summer', 'fall', 'winter'))
levels(data$season)
```
계절에 따른 y값의 모양을 상자그림을 통하여 실시하려고 한다.  
단 2가지 방법으로 표현해보도록 하자.(이후 표현은 ggplot으로 통일한다.)  

**A. Box Plot으로 그리기**

```{r}
boxplot(data$y ~ data$season)
```

**B. ggplot을 활용한 그림**

```{r}
ggplot(data = data, aes(x = season, y = y, color = season)) +
  geom_boxplot() +
  labs(title = 'Boxplot of Data' ,
       subtitle = 'Grouped by Season' ,
       x = 'Season')
```

 -> 계절에 따라 y(count)의 값이 크게 변동은 없는 것을 확인할 수 있다.

**holiday**

```{r}
data$holiday[which(data$holiday == 0)] <- 'holiday'
data$holiday[which(data$holiday == 1)] <- 'non holiday'
data$holiday <- as.factor(data$holiday)
str(data$holiday)
table(data$holiday)
```

-> Binary data 이며, Holiday와 Non holiday의 비율이 16879 : 500 인것을 확인할 수 있다.  
** 비율차이 시각화 **  


```{r}
D1 <- as.data.frame(table(data$holiday))

ggplot(data = D1, aes(x = Var1, y = Freq, fill = Var1)) +
  geom_col() +
  labs(title = 'Bar plot of frequency',
       subtitle = 'in Holiday variable') #+
  #stat_identity()
```

```{r}
ggplot(data = data, aes(x = holiday, y = y, color = holiday)) +
  geom_boxplot() +
  labs(title = 'Boxplot of Data' ,
       subtitle = 'Grouped by holiday',
       x = 'Holiday')# +
    #scale_x_discrete(labels = levels(data$holiday))

```

-> Holiday 유무에 따라 평균의 큰 차이는 없으나 큰 Y 값들이 
Holiday에 상대적으로 많은 것을 확인할 수 있다.  

**workingday**  

```{r}
data$workingday[which(data$workingday == 0)] <- 'non workingday'
data$workingday[which(data$workingday == 1)] <- 'workingday'
data$workingday <- as.factor(data$workingday)
table(data$workingday)
```
-> 1 : 2의 비율로 분포하는 것을 확인할 수 있다.  

** 비율차이 시각화 **  

```{r}
D1 <- as.data.frame(table(data$workingday))

ggplot(data = D1, aes(x = Var1, y = Freq, fill = Var1)) +
  geom_col() +
  labs(title = 'Bar plot of frequency',
       subtitle = 'in Workingday variable')
  #stat_identity()
```



차이점 확인하기.  
  
```{r}
ggplot(data = data) +
  geom_boxplot(aes(x = workingday, y = y, color = workingday)) +
  labs(title = 'Boxplot of Data' ,
       subtitle = 'Grouped by workingday',
       x = 'workingday') #+
    #scale_x_discrete(labels = levels(data$workingday))
```  
  
-> 평균의 차이가 크지 않은 것을 확인할 수 있다.  

**weather**  

범주별 데이터 수 확인  

```{r}
data$weather <- as.factor(data$weather)
table(data$weather)
```
-> 4(Heavy Rain)인 자료가 단 3개밖에 존재하지 않는다.  

차이점 확인

```{r}

ggplot(data = data) +
  geom_boxplot(aes(x = weather, y = y, color = weather)) +
  labs(title = 'Boxplot of Data' ,
       subtitle = 'Grouped by weather',
       x = 'weather') #+
    #scale_x_discrete(labels = levels(data$weather))
```

-> 범주 4의 치환이 필요함을 확인할 수 있고, 날씨에 따른 y의 변화를 확인할 수 있다.  

**Numerical data Exploring**  

temp, atemp, humidity, windspeed 모두 수치형 데이터이며, 이중 주목할 것은 temp(온도)와 atemp(체감온도) 일 것이다.  
-> 따라서 두 변수는 반드시 강한 상관관계를 가질 것으로 예상된다.  

```{r}
num_data <- data[, c('temp', 'atemp', 'humidity', 'windspeed')]
cor(num_data)
```
-> 예상대로 temp와 atemp의 상관관계를 확인할 수 있었다.  


**각 연속형 변수의 히스토그램과, 종속변수와의 상관계수 확인**  

test data에는 y값이 존재하지 않으므로, train data에서 numeric data를 추출하여 correlation을 계산한다.  


```{r}
num_train <- train[, c('temp', 'atemp', 'humidity', 'windspeed', 'y' ,'casual', 'registered')]
cor(num_train)
```

-> 각각의 상관계수를 확인할 수 있다.  

**Pair plot 그리기**  

시각화를 통해서 상관관계를 다시 확인한다.  

```{r}
corrplot(cor(num_train), method = 'circle', diag = FALSE)
```

-> 상관관계들을 확인할 수 있다.  

**각 연속형 변수들의 히스토그램**  

```{r}
temp_hist <- ggplot(data = num_data, aes(num_data$temp))+ geom_histogram() + labs(x = 'temp')
atemp_hist <- ggplot(data = num_data, aes(num_data$atemp))+ geom_histogram() + labs(x = 'atemp')
humidity_hist <- ggplot(data = num_data, aes(num_data$humidity))+ geom_histogram() + labs(x = 'humidity')
windspeed_hist <- ggplot(data = num_data, aes(num_data$windspeed))+ geom_histogram() + labs(x = 'windspeed')

grid.arrange(temp_hist, atemp_hist, humidity_hist, windspeed_hist, ncol=2, nrow = 2)
```
  
-> 알 수 있는 사실  
- humidity에서 100으로 관측된 값들을 세부적으로 봐야 한다. : 비오는 날의 습도는 100!  
- windspeed에서 0으로 관측된 값들(NA로 추청)이 보인다.


**Checking Y**

```{r}
ggplot(data = train, aes(train$y))+
     geom_histogram()
```

-> 왼쪽으로 치우친 것을 확인할 수 있으며, 변수변환의 필요성을 확인할 수 있다.  

-> 또한 변수의 성질(0 이상의 정수)에 따라서 Possion regression의 적합을 생각할 수 있다.  


**Checking additional Y (Casual & Registered)**   

본 데이터에는, casual(회원의 count) + registered(비회원의 count) = y(총 카운트 합) 으로 총 3가지의 종속변수가 존재한다고 볼 수 있다.  
분포의 차이를 확인하고 각각 다른 모형에 적합시키는 방법을 고려해 볼 수 있다.  

**기술통계량 비교**  

```{r}
summary(data$registered)
sd(data$registered, na.rm = TRUE)
summary(data$casual)
sd(data$casual, na.rm = TRUE)
```

**Box plot을 통한 비교**  

```{r}
ggplot(data = data) +
  geom_boxplot(aes(y = registered, fill = 'blue', alpha = 0.5)) +
  geom_boxplot(aes(y = casual, fill = 'red', alpha = 0.5)) +
  labs(title = 'Box plot of registered')
```

```{r}

A <- ggplot(data = data, aes(y = registered)) +
    geom_boxplot(fill = 'blue') +
    labs(title = 'Box plot of registered')
B <- ggplot(data = data, aes(y = casual)) +
    geom_boxplot(fill = 'red') +
    labs(title = 'Box plot of casual')
grid.arrange(A, B, ncol = 2)

```


**Histogram을 통한 비교**  

```{r}
A <- ggplot(data = data, aes(x = registered)) +
    geom_histogram(fill = 'blue') +
    labs(title = 'Histogram of registered')
B <- ggplot(data = data, aes(x = casual)) +
    geom_histogram(fill = 'red') +
    labs(title = 'Histogram of casual')
C <- ggplot(data = data, aes(x = y))+
    geom_histogram() +
    labs(title = 'Histogram of all y',
         subtitle = 'Sum of registered & casual')

grid.arrange(A, B, C, nrow = 3)

```

-> 두 종속변수의 구성요소가 명확히 다른 분포를 갖는 것을 확인할 수 있으며, 나누어 예측하는 것이 적절하다.  


```{r}
#workingday로 구분하여 확인하는 casual과 registered의 분포 차이
A <- ggplot(data = train, aes(x = datetime, y = casual, color = factor(workingday))) +
    geom_point() +
    labs(title = 'Scatter plot of data',
        subtitle = 'with datetime(casual)')
B <- ggplot(data = train, aes(x = datetime, y = registered, color = factor(workingday))) +
    geom_point() +
    labs(title = 'Scatter plot of data',
        subtitle = 'with datetime(registered)')
grid.arrange(A, B, nrow = 2)
```


#### EDA 정리

| 변수명 | 특징 | 전처리 방법 |
|-------|------|-------------|
| Datetime | 각 월의 20일 이후의 정보를 예측해야하며, 시계열성을 확인했다.| Lag변수를 만든다. |
| Season | 종속변수와의 큰 연관성을 찾을 수 없었다.  | X |
| Holiday | 두 범주값의 비율이 매우 비대칭이며, 종속변수와의 큰 연관성은 보이지 않는다. | X |
| Workingday | 종속변수와의 큰 연관성을 찾을 수 없었다. | X |
| Weather | 범주 4의 수가 3개로, 매우 적은 관측치를 보였다. | 유사한 다른 값으로 치환한다. |
| Temp | Atemp변수와의 높은 상관관계를 보인다. | 삭제 여부 검토 |
| Atemp | Temp변수와의 높은 상관관계를 보인다. | 삭제 여부 검토 |
| Humidity | 높은 수치를 기록한 값에서 공백이 보인다. | 100의 값은 비오는 날을 의미한다. |
| Windspeed | 0과 다른 수치 사이에 공백이 보인다. | 0이 결측값을 의미하는지 검토 |
| 종속변수 | y = casual + registered, 각기 다른 분포를 보인다. | 분할하여 예측했을 때, 유의한 변수 확인 |
---

### Data Preprocessing

**datetime**  

- 연월일 / 시간 -> 월별로 계절을 나누는게 어느정도 정확하지 않을까?  
- 시간대별로 다른 대여수? 버리고 싶지만, 시간대별로 온도가 너무 다르다.  

-> 시간대 별로 morning, afternoon, night, dawn 으로 나눠서 파생변수를 만들고 date time을 지우면 어떨까?    
너무 많은 정보의 삭제가 우려된다. 각 시간을 범주형으로 살리고, lag 변수를 만들어서 파생변수로 사용해보자.  

**시간 분할해서 plot그려보기.**  

```{r}
#sp <- unlist(strsplit(data$datetime, " "))
#시간 추출
#time <- sp[seq(from = 1, to = length(sp), by = 2)]
#table(time)
```

시간 분할
```{r}
sp <- unlist(strsplit(data$datetime, ":"))
#시간 추출
time <- substr(sp[seq(from = 1, to = length(sp), by = 2)], 12, 13)
#일시 추출
day <- substr(sp[seq(from = 1, to = length(sp), by = 2)], 1, 10)
day <- as.integer(gsub("-", "" , day, perl=TRUE))

data$time <- as.integer(time)
data$day <- as.numeric(factor(rank(day))) #일시를 단순한 순서로 변경

head(table(data$day), 20)
```



```{r}
ggplot(data = data, aes(x = day, y = y)) +
  geom_point() +
  labs(title = 'Scatter plot of data',
       subtitle = 'with time')
```

-> 일정한 추세를 보이는 것을 확인할 수 있었다.  
 
```{r}
same_time_idx <- which(data$time == 6)
same_time_data <- data[same_time_idx, ]

A1 <- ggplot(data = same_time_data, aes(x = datetime, y = registered, color = workingday)) +
  geom_point() +
  labs(title = 'Count of registered(Grouped by workingday)',
       subtitle = 'with sametime(ex.6AM)')

A2 <- ggplot(data = same_time_data, aes(x = datetime, y = casual, color = workingday)) +
  geom_point() +
  labs(title = 'Count of casual(Grouped by workingday)',
       subtitle = 'with sametime(ex.6AM)')

B1 <- ggplot(data = same_time_data, aes(x = datetime, y = registered, color = holiday)) +
  geom_point() +
  labs(title = 'Count of registered(Grouped by holiday)',
       subtitle = 'with sametime(ex.6AM)')

B2 <- ggplot(data = same_time_data, aes(x = datetime, y = casual, color = holiday)) +
  geom_point() +
  labs(title = 'Count of casual(Grouped by holiday)',
       subtitle = 'with sametime(ex.6AM)')

grid.arrange(A1, B1, A2, B2, nrow = 2, ncol = 2)
```
 
-> Workingday + registered 의 조합이 가장 두드러지게 분리된다.  

**연도, 월에 따른 비교**  

```{r}
data$year <- substr(data$datetime, 1, 4)
data$year <- as.factor(data$year)
data$month <- substr(data$datetime, 6, 7)
data$month <- as.factor(data$month)
```

**연도에 따른 차이**  

```{r}
A <- ggplot(data = data, aes(x = year, y = registered, color = year)) +
  geom_boxplot() +
  labs(title = 'Boxplot of registered in year')
B <- ggplot(data = data, aes(x = year, y = casual, color = year)) +
  geom_boxplot() +
  labs(title = 'Boxplot of casual in year')

grid.arrange(A, B, ncol=2)
```

-> 차이의 여부 확인  

**월에 따른 차이**  

```{r}
A <- ggplot(data = data, aes(x = month, y = registered, color = month)) +
  geom_boxplot() +
  labs(title = 'Boxplot of registered in month')
B <- ggplot(data = data, aes(x = month, y = casual, color = month)) +
  geom_boxplot() +
  labs(title = 'Boxplot of casual in month')

grid.arrange(A, B, nrow=2)
```

-> 일정한 추세 확인

datetime변수 삭제  

```{r}
data <- subset(data, select = -c(datetime))
```

-> datetime에서 일자를 사용하지 않는이유 : test와 train의 일자가 모두 다르기 때문.  

**Lagvariable in day**  
Lag변수에서 사용할 수 있는 변수를 선택한다. 

```{r}
#ggplot(data = data, aes(x = day, y = temp)) +
#  geom_point()


```

-> 문제점 발견! 1차 모델링 이후에 해결법 확인하기  

**season**  

EDA과정에서 약간의 영향력을 확인했기 때문에, 따로 처리하지 않도록 한다.  

**Holiday**   

위에서 확인한 boxplot을 확인해 보았을 때, 변수의 비율도 치우쳐있고 count에 큰 영향을 주는 것 같지 않다.
-> 지워버리자. workingday 데이터만 사용  


```{r}
data <- subset(data, select = -c(holiday))
```

**workingday**  

workingday 변수 역시 큰 영향을 끼치지 않아 보이지만, holiday 변수의 삭제로 인해 이 변수는 남겨놓고 분석을 시도해보기로 한다.  


**weather**  

4번 범주(악천후)에 속하는 데이터가 3개밖에 존재하지 않는 것을 확인했으므로, 이를 다른 범주로 치환해야 한다.  

```{r}
list(Index = which(data$weather == 4),
     Previous_day = data[which(data$weather == 4)-1,'weather'],
     Level4_day = data[which(data$weather == 4),'weather'],
     Next_day = data[which(data$weather == 4)+1,'weather'])
```
-> 3개의 데이터 모두 전후일에 날씨변수가 3이었다. 이에 따라서 모든 범주 4를 범주 3으로 치환한다.  

```{r}
data[which(data$weather == 4), 'weather'] = '3'
data$weather <- factor(data$weather) #범주4 제거
```

**Numeric data**  

Numeric data는 따로 처리하지 않도록 한다.  

-> 파생변수를 만들어서 한번에 처리할 수 있다면?  

**불쾌지수 변수 만들기**  

Discomfort = temp & humidity
```{r}
discomfort <- with(data, (9/5)*temp-
                     0.55*(1-(humidity/100))*((9/5)*temp-26)+32)
data$discomfort <- discomfort
```

**상관계수 확인하기(불쾌지수 추가)**  

```{r}
num_data_2 <- data[which(!is.na(data$y)), c('temp', 'atemp', 'humidity', 'windspeed','discomfort', 'y')]
cor(num_data_2)

# data <- subset(data, select = -c(temp, humidity))
```
-> temp와 atemp, humidity, discomfort와의 correlation을 확인하고, 변수 처리방안을 고민한다.  
-> 모형 적합 후에 삭제여부 검토  

**windspeed**  


Histogram  

```{r}
ggplot(data = data, aes(data$windspeed))+
     geom_histogram()
```

-> 0값이 상당히 많이 관측된 것을 확인할 수 있다. 이는 실제 값이 아닌 NA값일 확률이 높으므로(구간이 비어져있음),  
이를 대체할 방법을 찾는다.  

분포확인  
```{r}
length(table(data$windspeed))
```

총 30개의 값으로 분포, 연속형이 아닌 범주로 봐도 될까?  
-> 범주의 값에 따라서 편차가 크다.  
```{r}
barplot(table(data[which(data$windspeed != 0), "windspeed"]))
```


2180개의 결측값, 풍속에 영향을 줄 만한 변수는? : season, weather, temp, atemp, humidity, time, day, month, discomfort  

```{r}
# train_wind / test_wind / val_wind 데이터 분할
train_wind <- data[which(data$windspeed != 0), ]
test_wind <- data[which(data$windspeed == 0), ]
set.seed(1)
val_idx <- createDataPartition(train_wind$windspeed, p = 0.3, list = FALSE)
val_wind <- train_wind[val_idx, ]
tr_wind <- train_wind[-val_idx, ]
```

모형 적합전, train에 들어갈 formula(날씨변수)와 trainControl인자 설정  
```{r}
f_1 <- formula(windspeed ~ season + weather + temp + atemp + humidity + time + day + month + discomfort)
#파라메터 설정시에 진행할 CV방법 : 3repeated 5-fold cross validation
tc_1 <- trainControl(method = 'repeatedcv', 
                     number = 5,
                     repeats = 3)
```

**method1 . ctree2 사용. **  

```{r}
wind_model_tree <- train(f_1, method = 'ctree2',  trControl = tc_1, data = tr_wind) #ctree2는 maxdepth도 조절
plot(wind_model_tree$finalModel)
wind_pre <- predict(wind_model_tree, newdata = val_wind)
mean((wind_pre-val_wind$windspeed)^2)
```

**method2 . randomForest 사용. **   

```{r}
#학습시간 쒯~~~~ 해결방법은?
wind_model_rf <- train(f_1, method = 'ranger', 
                       importance = 'impurity', #impurity : 불순도를 통한 variableimportance
                       data = tr_wind) # rf(randomForest보다 빠르대!) trControl = tc_1,
wind_pre <- predict(wind_model_rf, newdata = val_wind)
mean((wind_pre-val_wind$windspeed)^2)
```

**Variable Importance plot in predicting windspeed**  

```{r}
imp_var <- data.frame(importance(wind_model_rf$finalModel))
Variable <- row.names(imp_var)
Importance <- imp_var[, 1]

imp_var <- data.frame('Variable' = Variable, 'Importance' = Importance)
imp_var <- imp_var[order(imp_var$Importance, decreasing = TRUE), ] #내림차순 정렬

imp_var_5 <- imp_var[c(1:5), ]
imp_var_7 <- imp_var[c(1:7), ]

imp_plot_5 <- ggplot(data = imp_var_5, aes(x = reorder(Variable, -Importance), y = Importance)) +
  geom_col() +
  labs(title = 'Variable Imp plot with 5 variable',
       x = 'Variable')

imp_plot_7 <- ggplot(data = imp_var_7, aes(x = reorder(Variable, -Importance), y = Importance)) +
  geom_col() +
  labs(title = 'Variable Imp plot with 7 variable',
       x = 'Variable')

imp_plot_all <- ggplot(data = imp_var, aes(x = reorder(Variable, -Importance), y = Importance)) +
  geom_col() +
  labs(title = 'Variable Imp plot with all variable',
       x = 'Variable')

grid.arrange(imp_plot_5, imp_plot_7, imp_plot_all, nrow = 3)
```

**method3 . 중앙값(Median)으로 대치 **  

```{r}
wind_pre_median <- median(tr_wind$windspeed)
mean((wind_pre_median - val_wind$windspeed)^2)
```

**method4 . 평균(Mean)으로 대치 **  

```{r}
wind_pre_mean <- mean(tr_wind$windspeed)
mean((wind_pre_mean - val_wind$windspeed)^2)
```

-> RandomForest로 결측값을 대체하자.  

**결측값(windspeed) 대체**  

```{r}
#포뮬러 설정 : 날씨변수
f_wind <- formula(windspeed ~ season + weather + temp + atemp + humidity + time + day + month + discomfort)

#파라메터 설정시에 진행할 CV방법 : 3repeated 5-fold cross validation
tc_wind <- trainControl(method = 'repeatedcv', 
                        number = 5,
                        repeats = 3)

wind_model_rf_final <- train(f_wind, method = 'ranger', 
                             importance = 'impurity',
                             trControl = tc_wind,
                             data = train_wind) # train_wind_a : 0이 아닌 값을 갖는 모든 데이터
wind_pre <- predict(wind_model_rf_final, newdata = test_wind)
test_wind$windspeed <- round(wind_pre, digits = 4) #4자리수까지 반올림 후, 대체
```

```{r}
data_baseline <- rbind(test_wind, train_wind)
```


**Lag변수**  

```{r}
#make new train / test data
data_baseline <- data_baseline[order(data_baseline$day, data_baseline$time), ] #order df with day & time
train_baseline <- data_baseline[!is.na(data_baseline$y), ]
test_baseline <- data_baseline[is.na(data_baseline$y), ]
#How can I make a lag Variable?
length(table(train_baseline$day)) * 24 - nrow(train_baseline) #58개의 NA를 갖는 time
length(table(test_baseline$day)) * 24 - nrow(test_baseline) # 107개의 NA를 갖는 time
#lag 변수를 만든뒤, merge를 진행하면? 165개의 추가 NA값이 생긴다. 
# -> lag변수에서 사용할 변수를 신중하게 선택해야 한다.
```

```{r}
ggplot(data = data_baseline, aes(x = (data_baseline$day + data_baseline$time/24), y = temp)) +
  geom_point(size = 0.3)
```

-> Lag변수 제외한 채로, 모형적합해보기.

**Baseline 완성**  

```{r}

save.image(file='BikeEnv.RData')
rm(list = ls())
load('C:\\BikeEnv.RData')
```


---  

###Modeling  

```{r}
str(data_baseline)
```

**Data preparing**  
data_baseline, train_baseline, test_baseline 3종류의 데이터 준비완료
```{r}
feature <- colnames(data_baseline)
```

**Linear regression**  

```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'month', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거
X_var <- setdiff(feature, N_var)
form_reg <- as.formula(paste('registered~', paste0(X_var, collapse = '+')))
form_cas <- as.formula(paste('casual~', paste0(X_var, collapse = '+')))
fitlm_reg <- lm(formula = form_reg, data = train_baseline)
fitlm_cas <- lm(formula = form_cas, data = train_baseline)
```

**모형 확인**  
```{r}
summary(fitlm_reg)
```

-> R스퀘어는 0.329로 잘 적합되지 않았다.  

**가정 확인**  

```{r}
par(mfrow = c(2,2))
plot(fitlm_reg)
mtext("lm registered", side = 3, line = -14, outer = TRUE)
plot(fitlm_cas)
mtext("lm casual", side = 3, line = -14, outer = TRUE)
```

-> 정규성에 대한 가정을 위배한다. 종속변수의 변환이 필요하다는 것을 확인할 수 있다.  

**Linear regression with Log-transformation**  
각각의 종속변수는 0이상의 정수이므로 1을 더한뒤에 log변환을 시도한다.  

```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'month', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거
X_var <- setdiff(feature, N_var)
form_log_reg <- as.formula(paste('log(registered+1)~', paste0(X_var, collapse = '+')))
form_log_cas <- as.formula(paste('log(casual+1)~', paste0(X_var, collapse = '+')))
fitlm_log_reg <- lm(formula = form_log_reg, data = train_baseline)
fitlm_log_cas <- lm(formula = form_log_cas, data = train_baseline)
```

**가정 확인**  

```{r}
par(mfrow = c(2,2))
plot(fitlm_log_reg)
mtext("Log transform lm registered", side = 3, line = -14, outer = TRUE)
plot(fitlm_log_cas)
mtext("Log transform lm casual", side = 3, line = -14, outer = TRUE)
```

-> 변환 전에 비해, 종속변수의 정규성에 있어서 나아진 모습을 보인다.  

**Interpretation of Regression**  
Casual : 로그변환한 선형회귀모형
```{r}
summary(fitlm_log_cas)
```

-> R스퀘어가 0.59로 향상된 모습을 보인다.  
-> 모든 변수가 유의하다는 것을 확인할 수 있다.  

Registered : 로그변환한 선형회귀모형
```{r}
summary(fitlm_log_reg)
```

-> R스퀘어가 0.46로 향상된 모습을 보인다.  
-> 모든 변수가 유의하다는 것을 확인할 수 있다.

**Return to Data partition**  

Train data를 T_model과 V_model data로 분할하여 각 모형을 평가하기로 한다.  

caret::createDataPartition을 활용한 data partition  

```{r}
set.seed(1)
train_baseline$time <- factor(train_baseline$time)
test_baseline$time <- factor(test_baseline$time)
Caret_idx_cas <- createDataPartition(train_baseline$casual, p = 0.8, list = FALSE) 
Caret_idx_reg <- createDataPartition(train_baseline$registered, p = 0.8, list = FALSE) 
T_model_cas <- train_baseline[Caret_idx_cas, ]
V_model_cas <- train_baseline[-Caret_idx_cas, ]
T_model_reg <- train_baseline[Caret_idx_reg, ]
V_model_reg <- train_baseline[-Caret_idx_reg, ]
```
-> set.seed()함수를 사용하여 매 시행마다 같은 데이터셋을 활용할 수 있도록 고정시킨다.  

**Linear regression(log transform) fitting**  
직전 확인한대로, 선택한 변수들로 모형을 적합시킨다. (다중공선성과 가정을 고려한 변수선택)

```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거 'month',
X_var <- setdiff(feature, N_var)

form_log_cas <- as.formula(paste('log(casual+1)~', paste0(X_var, collapse = '+')))
form_log_reg <- as.formula(paste('log(registered+1)~', paste0(X_var, collapse = '+')))

fitlm_log_cas <- lm(formula = form_log_cas, data = T_model_cas)
fitlm_log_reg <- lm(formula = form_log_reg, data = T_model_reg)
```


**모형 평가**  

```{r}
pred_cas <- exp(predict(fitlm_log_cas, newdata = V_model_cas))-1
pred_reg <- exp(predict(fitlm_log_reg, newdata = V_model_reg))-1

MSE_cas <- mean((V_model_cas$casual-pred_cas)^2)
MSE_reg <- mean((V_model_reg$registered-pred_reg)^2)
RMSE_cas <- sqrt(MSE_cas)
RMSE_reg <- sqrt(MSE_reg)
list(RMSE_cas = RMSE_cas, RMSE_reg = RMSE_reg)
```

-> RMSE_cas : 25.4308, RMSE_reg : 80.7288  

**Poisson regression**  

```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거 'month',
X_var <- setdiff(feature, N_var)

form_pr_cas <- as.formula(paste('casual~', paste0(X_var, collapse = '+')))
form_pr_reg <- as.formula(paste('registered~', paste0(X_var, collapse = '+')))

fitlm_pr_cas <- glm(formula = form_pr_cas ,
                    data = T_model_cas,
                    family = poisson)
fitlm_pr_reg <- glm(formula = form_pr_reg ,
                    data = T_model_reg,
                    family = poisson)
```

**모형 평가**  

```{r}
pred_cas <- predict(fitlm_pr_cas, newdata = V_model_cas)
pred_reg <- predict(fitlm_pr_reg, newdata = V_model_reg)

MSE_cas <- mean((V_model_cas$casual-pred_cas)^2)
MSE_reg <- mean((V_model_reg$registered-pred_reg)^2)

RMSE_cas <- sqrt(MSE_cas)
RMSE_reg <- sqrt(MSE_reg)
list(RMSE_cas = RMSE_cas, RMSE_reg = RMSE_reg)
```

-> RMSE_cas : 59.3863, RMSE_reg : 210.3224  

**Zero Inflated poisson regression **  
```{r}
#mat_f4 <- subset(T_model, select = c('season','workingday','weather','temp','atemp','humidity',
#                                                        'windspeed','time','year','discomfort'))
#fit4_reg <- zip.mod(T_model$y, mat_f4)

N_var <- c('y', 'casual', 'registered', 'season', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거 'month',
X_var <- setdiff(feature, N_var)

form_zi_cas <- as.formula(paste('casual~', paste0(X_var, collapse = '+'), '|1'))
form_zi_reg <- as.formula(paste('registered~', paste0(X_var, collapse = '+'), '|1'))

fitlm_zi_cas <- zeroinfl(formula = form_zi_cas,
                         data = T_model_cas)
fitlm_zi_reg <- zeroinfl(formula = form_zi_reg,
                         data = T_model_reg)
#fit4_real_y <- zeroinfl(y ~ 
#                       season + workingday + weather + temp + atemp + humidity + windspeed + time + year + discomfort|1, 
#                     data = T_model)
```

**모형평가**  

```{r}
pred_cas <- predict(fitlm_zi_cas, newdata = V_model_cas)
pred_reg <- predict(fitlm_zi_reg, newdata = V_model_reg)

MSE_cas <- mean((V_model_cas$casual-pred_cas)^2)
MSE_reg <- mean((V_model_reg$registered-pred_reg)^2)

RMSE_cas <- sqrt(MSE_cas)
RMSE_reg <- sqrt(MSE_reg)
list(RMSE_cas = RMSE_cas, RMSE_reg = RMSE_reg)
```

-> RMSE_cas : 21.47525, RMSE_reg : 70.57711  

**Ridge regression**
```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거 'month',
X_var <- setdiff(feature, N_var)

form_log_cas <- as.formula(paste('log(casual+1)~', paste0(X_var, collapse = '+')))
form_log_reg <- as.formula(paste('log(registered+1)~', paste0(X_var, collapse = '+')))

tc <- trainControl(method = 'repeatedcv', 
                   number = 5,
                   repeats = 3)

fitrr_log_cas <- train(form_log_cas, method = 'ridge',  data = T_model_cas) #trControl = tc, 
fitrr_log_reg <- train(form_log_reg, method = 'ridge',  data = T_model_reg) #trControl = tc, 
```

**모형 평가**  

```{r}
#pred_cas <- exp(predict(fitrl_log_cas, newdata = V_model_cas))-1
#pred_reg <- exp(predict(fitrl_log_reg, newdata = V_model_reg))-1

#MSE_cas <- mean((V_model_cas$casual-pred_cas)^2)
#MSE_reg <- mean((V_model_reg$registered-pred_reg)^2)
#RMSE_cas <- sqrt(MSE_cas)
#RMSE_reg <- sqrt(MSE_reg)
#list(RMSE_cas = RMSE_cas, RMSE_reg = RMSE_reg)
```

**앙상블**
```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거 'month',
X_var <- setdiff(feature, N_var)

#Linear regression, Ridge regression
form_log_cas <- as.formula(paste('log(casual+1)~', paste0(X_var, collapse = '+')))
form_log_reg <- as.formula(paste('log(registered+1)~', paste0(X_var, collapse = '+')))

#Poisson regression
form_pr_cas <- as.formula(paste('casual~', paste0(X_var, collapse = '+')))
form_pr_reg <- as.formula(paste('registered~', paste0(X_var, collapse = '+')))

#Zero-inflated poisson regression
form_zi_cas <- as.formula(paste('casual~', paste0(X_var, collapse = '+'), '|1'))
form_zi_reg <- as.formula(paste('registered~', paste0(X_var, collapse = '+'), '|1'))


#for Ridge alpha
tc <- trainControl(method = 'repeatedcv', 
                   number = 5,
                   repeats = 3)

fitlm_log_cas <- train(form_log_cas, method = 'lm', data = T_model_cas)
fitlm_log_reg <- train(form_log_reg, method = 'lm', data = T_model_reg)

fitrr_log_cas <- train(form_log_cas, method = 'ridge',  trControl = tc, data = T_model_cas)
fitrr_log_reg <- train(form_log_reg, method = 'ridge',  trControl = tc, data = T_model_reg)

fit_pr_cas <- train(form_pr_cas, method = 'glm',  family = 'poisson', data = T_model_cas)
fit_pr_reg <- train(form_pr_reg, method = 'glm',  family = 'poisson', data = T_model_reg)


fit_zi_cas <- zeroinfl(formula = form_zi_cas,
                         data = T_model_cas)
fit_zi_reg <- zeroinfl(formula = form_zi_reg,
                         data = T_model_reg)

pred_lm_cas <- exp(predict(fitlm_log_cas, newdata = V_model_cas))-1
pred_lm_reg <- exp(predict(fitlm_log_reg, newdata = V_model_reg))-1

#pred_rr_cas <- exp(predict(fitrr_log_cas, newdata = V_model_cas))-1
#pred_rr_reg <- exp(predict(fitrr_log_reg, newdata = V_model_reg))-1

pred_pr_cas <- predict(fit_pr_cas, newdata = V_model_cas)
pred_pr_reg <- predict(fit_pr_reg, newdata = V_model_reg)

pred_zi_cas <- predict(fit_zi_cas, newdata = V_model_cas)
pred_zi_reg <- predict(fit_zi_reg, newdata = V_model_reg)

ens_data_cas <- as.data.frame(cbind(pred_lm_cas, pred_pr_cas, pred_zi_cas, V_model_cas$casual)) # pred_rr_cas,
ens_data_reg <- as.data.frame(cbind(pred_lm_reg, pred_pr_reg, pred_zi_reg, V_model_reg$registered)) # pred_rr_reg, 

result_cas <- as.vector(apply(ens_data_cas, FUN = mean, MARGIN = 1))
RMSE_cas <- sqrt(mean((V_model_cas$casual-result_cas)^2))

result_reg <- as.vector(apply(ens_data_reg[,c(2:3)], FUN = mean, MARGIN = 1))
RMSE_reg <- sqrt(mean((V_model_reg$registered-result_reg)^2))
RMSE_reg

RMSE_reg <- sqrt(mean((V_model_reg$registered-result_reg)^2))


ggplot(data = ens_data_reg, aes(x = index(ens_data_reg), y = pred_pr_reg)) +
  geom_point() +
  geom_point(aes(x = index(ens_data_reg), y = V4, color = 'red')) #크고 작은 데이터들을 전혀 예측하지 못하네

ggplot(data = ens_data_cas, aes(x = index(ens_data_cas), y = pred_pr_cas)) +
  geom_point() +
  geom_point(aes(x = index(ens_data_cas), y = V4, color = 'red')) #얼추 예측이 잘 되는 듯
```

**최종모형 적합**  

평가결과 casual / registered 모두 Zero-inflated poission regression이 적합하다고 판단.

**Final model fitting**  

```{r}
N_var <- c('y', 'casual', 'registered', 'season', 'year', 'temp', 'atemp') # 다중공선성을 고려한 변수 제거 'month',
X_var <- setdiff(feature, N_var)

form_zi_cas <- as.formula(paste('casual~', paste0(X_var, collapse = '+'), '|1'))
form_zi_reg <- as.formula(paste('registered~', paste0(X_var, collapse = '+'), '|1'))

final_model_cas <- zeroinfl(formula = form_zi_cas,
                            data = train_baseline)
final_model_reg <- zeroinfl(formula = form_zi_reg,
                            data = train_baseline)

pred_cas <- predict(final_model_cas, newdata = test_baseline)
pred_reg <- predict(final_model_reg, newdata = test_baseline)
pred_y <- pred_reg + pred_cas
```
  
**Make sampleSubmission file with Final model** 

```{r}
sampleSubmission <- read.csv('sampleSubmission.csv', header = T)
sampleSubmission$count <- pred_y
write.csv(sampleSubmission, file = 'sampleSubmission_github.csv', row.names = FALSE)
```
  
---  

## 한계점  
 
 현재 점수는 WindSpeed(풍속) 변수의 0값이 많은 것을 적절한 값으로 채우지 못한 결과이다.  
즉 EDA과정에서 누락된 부분이 존재하므로, 추후에 수정과정을 통하여 더 나은 결과를 얻어야 할 것이다.
